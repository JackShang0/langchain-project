{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 提示词模板之ChatPromptTemplate",
   "id": "c9a83dabc163deaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1、 实例化的方式（两种方式：使用构造方法、form_message()）\n",
    "\n",
    "2、 调用提示词模板的几种方法：invoke()\\format()\\format_message()\\format_prompt()\n",
    "\n",
    "3、 丰富的实例化参数类似\n",
    "\n",
    "4、 结合LLM\n",
    "\n",
    "5、 插入消息列表：MessagePlaceholder"
   ],
   "id": "ba516b7290911819"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1、实例化的方法\n",
    "构造方法创建 ChatPromptTemplate"
   ],
   "id": "a106cc1a53855c7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T05:56:56.461878900Z",
     "start_time": "2026-01-30T05:56:56.392892800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder\n",
    "\n",
    "#  ------------ 构造方法创建\n",
    "chat_prompt = ChatPromptTemplate(messages=[\n",
    "    (\"system\",\"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\",\"我的问题是{question}\")\n",
    "]\n",
    "# , input_variables=[               #这个参数可有可无\n",
    "#     \"name\",\"question\",\n",
    "# ]\n",
    "\n",
    ")\n",
    "\n",
    "response = chat_prompt.invoke(input={\"name\":\"小智\",\"question\":\"1+2*5=\"})\n",
    "print(response)"
   ],
   "id": "adbd4b5ae9828d12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1+2*5=', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "调用from_message() 方法创建ChatPromptTemplate",
   "id": "bd23e35b362a590f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:01:38.427824400Z",
     "start_time": "2026-01-30T06:01:38.352282900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "#  ------------ from_messages 创建  --------------------- 两个方式创建所需的参数都是一致的\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "    (\"system\",\"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\",\"我的问题是{question}\")\n",
    "]\n",
    ")\n",
    "\n",
    "response = chat_prompt.invoke(input={\"name\":\"小智\",\"question\":\"1+2*5=\"})\n",
    "print(response)"
   ],
   "id": "88d52b46edfa0cec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1+2*5=', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2、调用提示词的几种方法\n",
    "- invoke()      重点记忆\n",
    "- format()\n",
    "- format_message()\n",
    "- format_prompt()"
   ],
   "id": "5a284d91c04d2212"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:08:54.337181800Z",
     "start_time": "2026-01-30T06:08:54.257285600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------format调用方式------------------\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "    (\"system\",\"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\",\"我的问题是{question}\")\n",
    "]\n",
    ")\n",
    "\n",
    "response = chat_prompt.format(name=\"小智\",question=\"1+2*5=\")\n",
    "print(response)\n",
    "print(type(response))"
   ],
   "id": "47cb5e68e8500fae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 你是一个AI助手，你的名字叫小智\n",
      "Human: 我的问题是1+2*5=\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:08:56.664714Z",
     "start_time": "2026-01-30T06:08:56.576528200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------format_messages调用方式------------------\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "    (\"system\",\"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\",\"我的问题是{question}\")\n",
    "]\n",
    ")\n",
    "\n",
    "response = chat_prompt.format_messages(name=\"小智\",question=\"1+2*5=\")\n",
    "print(response)\n",
    "print(type(response))\n"
   ],
   "id": "9aea6914f7acb3e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1+2*5=', additional_kwargs={}, response_metadata={})]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:51:05.406286200Z",
     "start_time": "2026-01-30T06:51:05.343866100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------format_prompt调用方式------------------\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "    (\"system\",\"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\",\"我的问题是{question}\")\n",
    "]\n",
    ")\n",
    "\n",
    "response = chat_prompt.format_prompt(name=\"小智\",question=\"1+2*5=\")\n",
    "print(response)\n",
    "print(type(response))\n",
    "\n",
    "\n",
    "# 将ChatPromptValue类型转换为消息构成的list\n",
    "response_message = response.to_messages()\n",
    "print(response_message)\n",
    "print(type(response_message))\n",
    "\n",
    "# 将ChatPromptValue类型转换为字符串类型\n",
    "response_message = response.to_string()\n",
    "print(response_message)\n",
    "print(type(response_message))"
   ],
   "id": "59f6e20e756e7542",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1+2*5=', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1+2*5=', additional_kwargs={}, response_metadata={})]\n",
      "<class 'list'>\n",
      "System: 你是一个AI助手，你的名字叫小智\n",
      "Human: 我的问题是1+2*5=\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3、更丰富的实例化参数类型（非重点）\n",
    "本质：不管使用构造方法、还是使用from_message()来创建ChatPromptTemplate的实例，本质上来讲，传入的都是消息构成的列表。\n",
    "\n",
    "从调用上来讲，我们看到，不管使用构造方法，还是使用from_message()，messages参数类型都是列表，但是列表元素的类型是多样的。可以是：\n",
    "字符串类型、字典类型、消息类型、元组构成的列表、Chat提示词模板类型、消息提示词模板类型"
   ],
   "id": "47ace54e057867b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3551785ee4d89468"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4、结合LLM",
   "id": "299d0eae274b9cf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T08:32:51.361557400Z",
     "start_time": "2026-01-30T08:32:44.651280700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1、 提供大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()    # 加载当前目录下的 .env 文件\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "os.environ.setdefault(\"OPENAI_BASE_URL\", os.getenv(\"OPENAI_BASE_URL\"))\n",
    "\n",
    "# 获取对话模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=20\n",
    ")\n",
    "\n",
    "\n",
    "# 2、通过Chat提示词模板、创建提示词\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "    (\"system\",\"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\",\"我的问题是{question}\")\n",
    "]\n",
    ")\n",
    "response = chat_prompt.invoke({\"name\":\"小白\",\"question\":\"1+2*5=\"})\n",
    "\n",
    "# 3、通过大模型调用提示词，得到响应数据\n",
    "result = model.invoke(response)\n",
    "print(result)\n",
    "print(type(result))"
   ],
   "id": "577e9956e54dffe9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我们按照运算顺序来计算：  \\n先算乘法 **2 × 5 = 10**，  \\n然后加法 **1 + 10 = 11**。  \\n\\n所以结果是：  \\n**1 + 2 × 5 = 11** ✅' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 21, 'total_tokens': 72, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 21}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '5ece9c8c-8396-476b-bc2e-7dc0c464d603', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c0e08-90f9-77d0-8e71-4aa877f31c97-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 21, 'output_tokens': 51, 'total_tokens': 72, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5、插入消息列表\n",
    "- 占位符功能：在提示词模板中预留位置，在运行时可以用实际的消息列表\n",
    "- 保持消息结构：能够确保插入的消息保持原有的消息类型，不会将这些消息转换成字符串。这样，模型可以区分不同角色发送的消息\n",
    "- 灵活性：可以用于构建复杂的对话流程，例如，我们可以将整个对话历史、或者某些中间步骤的消息动态的放入提示中\n",
    "- 使用场景\n",
    "    - 多轮对话\n",
    "    - 动态消息插入\n",
    "当不确定消息提示模板使用什么角色，或者系统在格式化过程中插入消息列表时，该怎么办？这就需要使用MessagesPlaceholder，负责在特定位置添加消息列表"
   ],
   "id": "c73255682faf7556"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T09:10:21.860380400Z",
     "start_time": "2026-01-30T09:10:16.078186300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import MessagesPlaceholder\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "        (\"human\", \"我的问题是{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 当不确定使用system还是human的时候，我们可以使用MessagesPlaceholder\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "response = chat_prompt.invoke({\n",
    "    \"name\": \"小白\",\n",
    "    \"msgs\": [HumanMessage(content=\"我的问题是：1+2*5=\"), AIMessage(content=\"1+3*6=？\")]\n",
    "})\n",
    "print(response)"
   ],
   "id": "2cdedffbad980ed7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小白', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是：1+2*5=', additional_kwargs={}, response_metadata={}), AIMessage(content='1+3*6=？', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "存储历史对话记录",
   "id": "1a61d9f58a0aafb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T02:27:13.010277300Z",
     "start_time": "2026-02-02T02:27:08.207321500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import MessagesPlaceholder\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        MessagesPlaceholder(\"history\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "prompt = chat_prompt.format_messages(\n",
    "    history=[HumanMessage(content=\"我的问题是：1+2*3=？\"), AIMessage(content=\"1+2*3=7\")],\n",
    "    question=\"我刚才的问题是什么？\")\n",
    "\n",
    "\n",
    "# 1、 提供大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()    # 加载当前目录下的 .env 文件\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "os.environ.setdefault(\"OPENAI_BASE_URL\", os.getenv(\"OPENAI_BASE_URL\"))\n",
    "\n",
    "# 获取对话模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=20\n",
    ")\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "print(result)"
   ],
   "id": "a3345582ea71af51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你刚才的问题是：**“1+2*3=？”**  \\n\\n答案是 **7**（按照运算顺序：先乘除后加减，所以先算 2×3=6，再加 1 得到 7）。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 34, 'total_tokens': 82, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 34}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '1095c0f1-3e39-4ccd-ae10-2e2bb5a82484', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c1c2c-e559-7983-af56-7254cd04c6d8-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 34, 'output_tokens': 48, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "557aec0c493b73db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
