{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1、 获取大模型",
   "id": "c067713f7a223b60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T02:16:38.228674900Z",
     "start_time": "2026-01-27T02:16:00.168366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "# 导入 dotenv 库 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()    # 加载当前目录下的 .env 文件\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "os.environ.setdefault(\"OPENAI_BASE_URL\", os.getenv(\"OPENAI_BASE_URL\"))\n",
    "\n",
    "# 创建大模型实例\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")    # 默认使用gtp-3.5-turbo\n",
    "\n",
    "# 1. 设置模型\n",
    "# 1.1 大语言模型\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\")  # 调用大模型   默认使用gpt-3.5-turbo\n",
    "\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型\")\n",
    "print(response)"
   ],
   "id": "e1c4ec3ad332d7d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好！这是一个非常重要且核心的问题。简单来说，**大模型（Large Language Model，简称LLM）** 是一种基于海量数据训练的、参数规模巨大（通常达到数十亿甚至数万亿级别）的深度学习模型，它能够理解、生成和推理人类语言（以及代码、图像等多模态信息）。\\n\\n我们可以从几个关键维度来理解它：\\n\\n### 1. 核心特征：“大”在哪里？\\n*   **参数规模巨大**：参数是模型从数据中学到的“知识”和“规则”。大模型的参数量动辄百亿、千亿，比如GPT-3有1750亿参数，GPT-4等更大模型的参数规模未公开但推测更大。更多的参数意味着更强的记忆和表达能力。\\n*   **训练数据海量**：它们通常在几乎整个互联网的文本（书籍、文章、网页、代码等）上进行训练，数据量可达TB甚至PB级别。这赋予了它们广泛的“世界知识”。\\n*   **计算资源消耗巨大**：训练一个大模型需要成千上万个高性能GPU/TPU工作数周甚至数月，耗资巨大（数百万到数千万美元），只有少数大型研究机构或公司有能力进行。\\n\\n### 2. 核心能力：能做什么？\\n大模型的核心是 **“预测下一个词”** 。基于这个基础，它们涌现出了惊人的能力：\\n*   **自然语言理解与生成**：流畅地进行对话、撰写文章、总结摘要、翻译语言。\\n*   **复杂推理**：解决逻辑问题、进行数学计算、分析因果关系。\\n*   **代码生成与理解**：编写、解释、调试多种编程语言的代码。\\n*   **多模态能力**：最新的模型（如GPT-4V、Gemini）不仅能处理文本，还能理解和生成图像、音频、视频等内容。\\n*   **工具使用**：可以通过API调用外部工具，如搜索引擎、计算器、专业软件，来扩展自身能力。\\n\\n### 3. 技术基础：Transformer架构\\n几乎所有现代大模型都基于 **Transformer** 架构（由谷歌在2017年提出）。其核心是 **“自注意力机制”** ，允许模型在处理一个词时，同时关注输入序列中的所有其他词，从而更好地理解上下文和长距离依赖关系。这是大模型性能突破的关键。\\n\\n### 4. 代表性模型\\n*   **GPT系列**：OpenAI开发，如ChatGPT（基于GPT-3.5/GPT-4），是推动大模型普及的里程碑。\\n*   **Gemini**：Google DeepMind开发的多模态模型。\\n*   **Claude**：Anthropic开发，注重安全性和长上下文。\\n*   **Llama系列**：Meta开源的大模型，推动了开源社区的发展。\\n*   **文心一言、通义千问、Kimi等**：中国公司开发的优秀大模型。\\n\\n### 5. 与大模型相关的关键概念\\n*   **预训练 + 微调**：\\n    *   **预训练**：在海量无标注数据上训练，让模型学会语言的通用模式和知识。这是最耗资源的一步。\\n    *   **微调**：在特定任务（如对话、法律文本）的标注数据上进一步训练，使模型适应具体需求。\\n*   **提示工程**：通过设计巧妙的输入提示（Prompt），来引导大模型输出更准确、更符合期望的结果。\\n*   **涌现能力**：当模型规模超过某个临界点后，会突然出现一些在较小模型中没有的复杂能力（如推理、思维链）。\\n\\n### 6. 重要意义与挑战\\n*   **意义**：大模型是通向**通用人工智能（AGI）** 的重要路径之一，正在重塑人机交互方式，成为新的生产力工具和基础设施。\\n*   **挑战**：\\n    *   **幻觉**：模型可能会生成看似合理但事实上错误或编造的内容。\\n    *   **偏见与安全**：可能继承和放大训练数据中的社会偏见，或被用于生成有害信息。\\n    *   **能耗与成本**：训练和运行成本极高，带来环境和经济可持续性问题。\\n    *   **可解释性**：其内部的决策过程像一个“黑箱”，难以完全理解。\\n\\n### 简单比喻\\n你可以把大模型想象成一个 **“博览群书、过目不忘的超级实习生”**：\\n*   它读遍了互联网上的所有文字（**海量数据**）。\\n*   它的大脑神经元连接异常复杂和庞大（**巨大参数**）。\\n*   它的核心工作是：根据你给出的前半句话，猜出最合理的后半句（**预测下一个词**）。\\n*   通过这种方式，它能回答问题、写文章、编代码，看起来就像拥有了智能。\\n\\n**总结来说，大模型是当前人工智能领域最前沿、最具影响力的技术范式，它不仅是强大的聊天工具，更是一个理解并生成复杂内容的通用基础平台，正在深刻改变科技、商业和社会的方方面面。**' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1026, 'prompt_tokens': 7, 'total_tokens': 1033, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 7}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'd676535b-989a-4015-ac76-cff5f4066e93', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bfd3c-8a21-70a0-acc9-7fa9a97a6158-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 7, 'output_tokens': 1026, 'total_tokens': 1033, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2、 使用提示词模板",
   "id": "52c752daf16dd656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T02:23:39.342080400Z",
     "start_time": "2026-01-27T02:22:58.739423500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"你是世界级的技术文档编写者\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 然后使用实例调用 format_messages\n",
    "messages = prompt.format_messages(input=\"大模型中的LangChain是什么\")\n",
    "\n",
    "# 我们可以把prompt和具体的llm的调用放在一起\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\":\"大模型中的LangChain是什么？\"})\n",
    "print(message)"
   ],
   "id": "ff386f566e24bc85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**LangChain** 是一个用于构建**基于大语言模型（LLM）的应用程序**的开源框架。它不是一个独立的模型，而是一个强大的“工具箱”和“连接器”，旨在帮助开发者更高效地将大模型（如 GPT-4、Llama 等）与外部数据源、计算工具和应用环境结合起来，从而创建出功能强大、实用的 AI 应用。\\n\\n简单来说，LangChain 的核心目标是**解决大模型在现实应用中的两大核心局限**：\\n1.  **缺乏“记忆”和“上下文”**：普通的大模型调用是独立的，无法记住之前的对话或信息。\\n2.  **知识截止与无法执行动作**：大模型的知识有截止日期，且自身无法直接读取外部数据、进行计算或操作外部系统。\\n\\n---\\n\\n### LangChain 的核心概念与组件\\n\\nLangChain 通过以下几个关键模块来实现其功能：\\n\\n#### 1. **模型（Models）**\\n   - **LLM**： 对接各种大语言模型（如 OpenAI、Anthropic、Hugging Face 等）。\\n   - **聊天模型**： 专门为对话优化的模型。\\n   - **嵌入模型**： 将文本转换为向量，用于检索和比较。\\n\\n#### 2. **提示（Prompts）**\\n   - 提供模板化、动态构建提示词的功能，使与模型的交互更可控、更高效。\\n   - 例如，可以创建一个包含用户输入、上下文和历史对话的标准化提示模板。\\n\\n#### 3. **链（Chains）**\\n   - **这是 LangChain 的灵魂**。它将多个组件（模型、提示、工具等）按顺序或逻辑组合成一个完整的处理流程。\\n   - 例如，一个链可以是：`用户输入 -> 检索相关文档 -> 组合成提示 -> 发送给 LLM -> 解析输出`。\\n   - 常见的链有 `LLMChain`、`SequentialChain` 以及更复杂的 `RetrievalQA` 链。\\n\\n#### 4. **索引与检索（Indexes & Retrieval）**\\n   - 这是让大模型能够访问**私有或特定领域数据**的关键。\\n   - 过程通常是：将外部文档（如 PDF、数据库、网页）进行分割、嵌入成向量，存入向量数据库（如 Pinecone、Chroma、Weaviate）。\\n   - 当用户提问时，先从向量数据库中检索出最相关的文档片段，然后将这些片段作为上下文与问题一起交给大模型生成答案。这就是 **RAG（检索增强生成）** 的核心实现。\\n\\n#### 5. **记忆（Memory）**\\n   - 为链或代理提供“记忆”能力，使其能记住对话历史或之前的交互信息。\\n   - 例如 `ConversationBufferMemory` 可以保存完整的对话历史。\\n\\n#### 6. **代理（Agents）**\\n   - **这是 LangChain 最强大的特性之一**。代理让大模型具备“决策”和“使用工具”的能力。\\n   - 代理根据用户的目标，动态地决定调用哪个工具（如搜索网络、查询数据库、执行代码、调用 API），并组合多个步骤来完成复杂任务。\\n   - 例如，用户问“现在上海天气如何，用摄氏度告诉我”，代理可以决定先调用“搜索工具”获取天气信息，再调用“计算工具”进行单位换算。\\n\\n#### 7. **工具（Tools）**\\n   - 代理可以调用的具体功能，如 Google 搜索、Python 解释器、数据库连接、任意 API 等。\\n\\n---\\n\\n### LangChain 的主要应用场景\\n\\n1.  **构建智能聊天机器人**： 不仅是闲聊，更是能基于特定知识库（如公司文档、产品手册）进行问答的客服机器人。\\n2.  **文档分析与问答**： 上传多个文档（报告、合同、书籍），然后像专家一样对文档内容进行深度提问和总结。\\n3.  **智能数据分析与可视化**： 用自然语言让代理连接数据库、执行 SQL 查询，并生成图表。\\n4.  **自动化工作流**： 将大模型作为大脑，串联起多个软件和 API，自动完成写邮件、生成报告、整理数据等任务。\\n5.  **代码分析与生成**： 结合代码知识库和工具，进行代码解释、调试、生成和重构。\\n\\n### 一个简单的比喻\\n\\n如果把大模型（如 GPT-4）比作一个**知识渊博但“与世隔绝”的大脑**，那么：\\n- **LangChain 就是为这个大脑配备的“肢体”和“感官”**。\\n- **记忆模块**是它的笔记本。\\n- **检索系统**是它的私人图书馆和搜索引擎。\\n- **代理和工具**是它的手和脚，让它能操作电脑、上网、计算。\\n- **链**是它处理复杂问题时的标准化工作流程。\\n\\n### 总结\\n\\n**LangChain 是一个赋能框架**，它极大地降低了大语言模型的应用开发门槛，让开发者能够聚焦于业务逻辑，快速构建出能够理解、推理并作用于真实世界信息的下一代 AI 应用。它已成为当前大模型应用开发领域最流行和最重要的工具之一。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1074, 'prompt_tokens': 18, 'total_tokens': 1092, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 18}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'ece507b4-4b30-47f6-b7b9-0a85a8e50d16', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bfd42-e6bb-7c81-9bac-2f2167f73222-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 18, 'output_tokens': 1074, 'total_tokens': 1092, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3、 使用输出解析器",
   "id": "740ee5438351b700"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T02:28:52.782185800Z",
     "start_time": "2026-01-27T02:28:46.365594700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 初始化模型\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\")\n",
    "\n",
    "# 创建提示词模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术文档编写者\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 使用输出解析器\n",
    "output = JsonOutputParser()\n",
    "\n",
    "# 将其添加到上一个链中\n",
    "chain = prompt | llm | output\n",
    "\n",
    "# 调用它并提出同样的问题，答案是一个字符串，而不是ChatMessage\n",
    "chain.invoke({\"input\":\"LangChain是什么？用JSON格式回复，问题调用question，回答用answer\"})"
   ],
   "id": "45bded66c9865433",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'LangChain是什么？',\n",
       " 'answer': 'LangChain是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。它提供了一套工具、组件和接口，简化了构建基于LLM的应用的过程，如聊天机器人、智能代理、文档问答系统等。LangChain的核心思想是通过“链”（Chains）将多个组件组合起来，以便处理复杂的任务，例如：连接外部数据源、管理对话历史、调用工具或API等。它支持多种LLM提供商（如OpenAI、Hugging Face等），并包含丰富的模块来处理提示模板、内存管理、索引检索等常见需求。'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4、 使用向量存储",
   "id": "3d064032b74bb036"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 安装本地向量数据库\n",
    "# pip/conda install faiss-cpu\n",
    "# pip/conda install langchain_community=0.3.7"
   ],
   "id": "9e85acf0fc86dfcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T04:21:49.097041Z",
     "start_time": "2026-01-27T04:21:32.361679600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#导包和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://blog.csdn.net/nkd50000/article/details/103199210\",\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(id=\"UCAP-CONTENT\"))\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 对于嵌入模型，这里通过API调用\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model=r\"E:\\shangdj\\python\\rag\\model_dir\\BAAI\\bge-large-zh-v1___5\")\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embeddings-ada-002\")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 使用分割器分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(len(documents))\n",
    "# 向量存储 embeddings 会将 documents 中的每个文本片段转换为向量，并将这些向量存储在 FAISS 向量数据库中\n",
    "vector = FAISS.from_documents(documents,embeddings)\n"
   ],
   "id": "94d98cb9889e919e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 391/391 [00:00<00:00, 825.09it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: E:\\shangdj\\python\\rag\\model_dir\\BAAI\\bge-large-zh-v1___5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 26\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(documents))\n\u001B[32m     25\u001B[39m \u001B[38;5;66;03m# 向量存储 embeddings 会将 documents 中的每个文本片段转换为向量，并将这些向量存储在 FAISS 向量数据库中\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m vector = \u001B[43mFAISS\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:813\u001B[39m, in \u001B[36mVectorStore.from_documents\u001B[39m\u001B[34m(cls, documents, embedding, **kwargs)\u001B[39m\n\u001B[32m    810\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(ids):\n\u001B[32m    811\u001B[39m         kwargs[\u001B[33m\"\u001B[39m\u001B[33mids\u001B[39m\u001B[33m\"\u001B[39m] = ids\n\u001B[32m--> \u001B[39m\u001B[32m813\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1044\u001B[39m, in \u001B[36mFAISS.from_texts\u001B[39m\u001B[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001B[39m\n\u001B[32m   1025\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001B[39;00m\n\u001B[32m   1026\u001B[39m \n\u001B[32m   1027\u001B[39m \u001B[33;03mThis is a user friendly interface that:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1041\u001B[39m \u001B[33;03m        faiss = FAISS.from_texts(texts, embeddings)\u001B[39;00m\n\u001B[32m   1042\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1043\u001B[39m embeddings = embedding.embed_documents(texts)\n\u001B[32m-> \u001B[39m\u001B[32m1044\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__from\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1045\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1046\u001B[39m \u001B[43m    \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1047\u001B[39m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1048\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1049\u001B[39m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1050\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1051\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1001\u001B[39m, in \u001B[36mFAISS.__from\u001B[39m\u001B[34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001B[39m\n\u001B[32m    998\u001B[39m     index = faiss.IndexFlatIP(\u001B[38;5;28mlen\u001B[39m(embeddings[\u001B[32m0\u001B[39m]))\n\u001B[32m    999\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1000\u001B[39m     \u001B[38;5;66;03m# Default to L2, currently other metric types not initialized.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1001\u001B[39m     index = faiss.IndexFlatL2(\u001B[38;5;28mlen\u001B[39m(\u001B[43membeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m))\n\u001B[32m   1002\u001B[39m docstore = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mdocstore\u001B[39m\u001B[33m\"\u001B[39m, InMemoryDocstore())\n\u001B[32m   1003\u001B[39m index_to_docstore_id = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mindex_to_docstore_id\u001B[39m\u001B[33m\"\u001B[39m, {})\n",
      "\u001B[31mIndexError\u001B[39m: list index out of range"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a01eef0ca704c671"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T06:10:13.192504500Z",
     "start_time": "2026-01-27T06:09:54.056119900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导包和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import bs4\n",
    "\n",
    "# 1. 加载文档\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://blog.csdn.net/nkd50000/article/details/103199210\",\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(id=\"UCAP-CONTENT\"))\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. 分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 每个块的大小\n",
    "    chunk_overlap=50  # 块之间的重叠\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3. 创建嵌入模型（使用本地模型）\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=r\"E:\\shangdj\\python\\rag\\model_dir\\BAAI\\bge-large-zh-v1___5\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# 4. 创建向量存储\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "print(f\"加载了 {len(docs)} 个文档\")\n",
    "print(f\"分割为 {len(split_docs)} 个块\")\n",
    "print(\"向量存储已创建\")"
   ],
   "id": "4f5df144863bfdfc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\kingdee\\AppData\\Local\\Temp\\ipykernel_21552\\3894391510.py:23: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Loading weights: 100%|██████████| 391/391 [00:00<00:00, 782.76it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: E:\\shangdj\\python\\rag\\model_dir\\BAAI\\bge-large-zh-v1___5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     23\u001B[39m embeddings = HuggingFaceEmbeddings(\n\u001B[32m     24\u001B[39m     model_name=\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mE:\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mshangdj\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mpython\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mrag\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mmodel_dir\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mBAAI\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mbge-large-zh-v1___5\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     25\u001B[39m     model_kwargs={\u001B[33m'\u001B[39m\u001B[33mdevice\u001B[39m\u001B[33m'\u001B[39m: \u001B[33m'\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m'\u001B[39m},\n\u001B[32m     26\u001B[39m     encode_kwargs={\u001B[33m'\u001B[39m\u001B[33mnormalize_embeddings\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m}\n\u001B[32m     27\u001B[39m )\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# 4. 创建向量存储\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m vectorstore = \u001B[43mFAISS\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_docs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m加载了 \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(docs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m 个文档\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     33\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m分割为 \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(split_docs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m 个块\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:813\u001B[39m, in \u001B[36mVectorStore.from_documents\u001B[39m\u001B[34m(cls, documents, embedding, **kwargs)\u001B[39m\n\u001B[32m    810\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(ids):\n\u001B[32m    811\u001B[39m         kwargs[\u001B[33m\"\u001B[39m\u001B[33mids\u001B[39m\u001B[33m\"\u001B[39m] = ids\n\u001B[32m--> \u001B[39m\u001B[32m813\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1044\u001B[39m, in \u001B[36mFAISS.from_texts\u001B[39m\u001B[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001B[39m\n\u001B[32m   1025\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001B[39;00m\n\u001B[32m   1026\u001B[39m \n\u001B[32m   1027\u001B[39m \u001B[33;03mThis is a user friendly interface that:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1041\u001B[39m \u001B[33;03m        faiss = FAISS.from_texts(texts, embeddings)\u001B[39;00m\n\u001B[32m   1042\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1043\u001B[39m embeddings = embedding.embed_documents(texts)\n\u001B[32m-> \u001B[39m\u001B[32m1044\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__from\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1045\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1046\u001B[39m \u001B[43m    \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1047\u001B[39m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1048\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1049\u001B[39m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1050\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1051\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1001\u001B[39m, in \u001B[36mFAISS.__from\u001B[39m\u001B[34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001B[39m\n\u001B[32m    998\u001B[39m     index = faiss.IndexFlatIP(\u001B[38;5;28mlen\u001B[39m(embeddings[\u001B[32m0\u001B[39m]))\n\u001B[32m    999\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1000\u001B[39m     \u001B[38;5;66;03m# Default to L2, currently other metric types not initialized.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1001\u001B[39m     index = faiss.IndexFlatL2(\u001B[38;5;28mlen\u001B[39m(\u001B[43membeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m))\n\u001B[32m   1002\u001B[39m docstore = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mdocstore\u001B[39m\u001B[33m\"\u001B[39m, InMemoryDocstore())\n\u001B[32m   1003\u001B[39m index_to_docstore_id = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mindex_to_docstore_id\u001B[39m\u001B[33m\"\u001B[39m, {})\n",
      "\u001B[31mIndexError\u001B[39m: list index out of range"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5、 RAG（检索增强生成）",
   "id": "29ec883747f8523e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T06:21:02.729693300Z",
     "start_time": "2026-01-27T06:20:55.526136900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retriever.search_kwargs = {\"k\":3}\n",
    "docs = retriever.invoke(\"建设用地使用权是什么\")\n",
    "\n",
    "# 6. 定义提示词模板\n",
    "prompt_template = \"\"\"\n",
    "            请严格扮演一个信息提取助手的角色。你的任务是根据提供的【参考文档】来回答问题。\n",
    "\n",
    "            【参考文档开始】\n",
    "            {info}\n",
    "            【参考文档结束】\n",
    "\n",
    "            规则：\n",
    "            1.  你的回答必须完全基于上述参考文档。如果答案未在文档中明确提及，你必须说“文档中未提及相关信息”。\n",
    "            2.  不要引入文档以外的知识或假设。\n",
    "            3.  如果文档中的信息相互矛盾，请指出这一点。\n",
    "            4.  在回答的最后，用括号注明答案所依据的文档句子编号（例如：基于[1][3]）。\n",
    "\n",
    "            问题：{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 7. 得到提示词模板对象\n",
    "template = PromptTemplate.from_messages(prompt_template)\n",
    "\n",
    "# 8. 得到提示词对象\n",
    "prompt = template.format(info=docs,question='建设用地使用权是什么？')\n",
    "\n",
    "# 9. 调用LLM\n",
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ],
   "id": "4e5e5e6ebdcd883b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprompts\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PromptTemplate\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m retriever = \u001B[43mvector\u001B[49m.as_retriever()\n\u001B[32m      4\u001B[39m retriever.search_kwargs = {\u001B[33m\"\u001B[39m\u001B[33mk\u001B[39m\u001B[33m\"\u001B[39m:\u001B[32m3\u001B[39m}\n\u001B[32m      5\u001B[39m docs = retriever.invoke(\u001B[33m\"\u001B[39m\u001B[33m建设用地使用权是什么\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'vector' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6、 使用Agent",
   "id": "215515f55dfe8d9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T06:23:22.404150300Z",
     "start_time": "2026-01-27T06:23:15.430043900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "#\n",
    "#\n",
    "# retriever_tool = create_retriever_tool(\n",
    "#     retriever,\n",
    "#     \"CivilCodeRetriever\",\n",
    "#     \"搜索有关中华人民共和国民法典的信息，关于中华人民共和国民法典的任何问题，您必须使用此工具！\",\n",
    "# )\n",
    "#\n",
    "# tools = [retriever_tool]\n",
    "#\n",
    "#\n",
    "# from langchain import hub\n",
    "# from langchain.agents import create_openai_functions_agent\n",
    "# from langchain.agents import AgentExecutor"
   ],
   "id": "4c4f69dfe5fdbfdc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\shangdj\\python\\env\\conda\\envs\\myPython3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.tools.retriever'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtools\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mretriever\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_retriever_tool\n\u001B[32m      2\u001B[39m retriever_tool = create_retriever_tool()\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'langchain.tools.retriever'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2f762635ca5b7f41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
